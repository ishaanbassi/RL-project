{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from wrappers import make_atari, wrap_deepmind, wrap_pytorch\n",
    "import queue\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd \n",
    "import os \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, init_std = 0.5):\n",
    "        super(NoisyNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.weights_mu = nn.Parameter(torch.empty(out_channels, in_channels)) \n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_channels))\n",
    "        self.weights_sigma = nn.Parameter(torch.empty(out_channels, in_channels))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_channels))\n",
    "        self.register_buffer('weight_epsilon',torch.empty(out_channels, in_channels))\n",
    "        self.register_buffer('bias_epsilon',torch.empty(out_channels))\n",
    "        self.init_std = init_std\n",
    "        self.resetNoise()\n",
    "        self.resetWeights()\n",
    "       \n",
    "   \n",
    "    def resetNoise(self):\n",
    "        epsilon_i = torch.randn(self.in_channels)\n",
    "        epsilon_i = epsilon_i.sign().mul_(epsilon_i.abs().sqrt_())\n",
    "        epsilon_j = torch.randn(self.out_channels)\n",
    "        epsilon_j = epsilon_j.sign().mul_(epsilon_j.abs().sqrt_())\n",
    "        self.weight_epsilon.copy_(epsilon_j.ger(epsilon_i))\n",
    "        self.bias_epsilon.copy_(epsilon_j)\n",
    "       \n",
    "   \n",
    "    def resetWeights(self):\n",
    "        mu_range = 1 / math.sqrt(self.in_channels)\n",
    "        self.weights_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weights_sigma.data.fill_(self.init_std / math.sqrt(self.in_channels))\n",
    "        self.bias_sigma.data.fill_(self.init_std / math.sqrt(self.out_channels))\n",
    "       \n",
    "   \n",
    "    def forward(self, input):\n",
    "        if not self.training:\n",
    "            return F.linear(input, self.weights_mu, self.bias_mu)\n",
    "        else:\n",
    "            weights = self.weights_mu + self.weights_sigma * self.weight_epsilon\n",
    "            biases = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "            return F.linear(input, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(torch.nn.Module):\n",
    "    def __init__(self,obs_shape,act_shape,atoms):\n",
    "        super(QNet, self).__init__()\n",
    "        self.atoms = atoms\n",
    "        self.act_shape = act_shape\n",
    "\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "#         self.fc1 = nn.Linear(7*7*64,512)\n",
    "#         self.fc2 = nn.Linear(512,1)\n",
    "#         self.fc3 = nn.Linear(7*7*64,512)\n",
    "#         self.fc4 = nn.Linear(512,act_shape)\n",
    "        self.fc1 = NoisyNet(7*7*64,512)\n",
    "        self.fc2 = NoisyNet(512,atoms)\n",
    "        self.fc3 = NoisyNet(7*7*64,512)\n",
    "        self.fc4 = NoisyNet(512,act_shape*atoms)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x/255\n",
    "        \n",
    "        #Conv\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        #Fc\n",
    "        x1 = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        v = self.fc2(x)\n",
    "        \n",
    "        x1 = self.fc3(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        adv = self.fc4(x1)\n",
    "        \n",
    "        #Reshaping value and advantage functions to add probabilities of each atom for each action\n",
    "        value = v.view(v.shape[0],1,self.atoms)\n",
    "        adv = adv.view(adv.shape[0],self.act_shape,self.atoms)\n",
    "        \n",
    "        q_s_a = value + adv - adv.mean(1,keepdim=True)\n",
    "        \n",
    "        #probability of each atom for all actions\n",
    "        q_s_a = self.softmax(q_s_a)\n",
    "        \n",
    "        return q_s_a\n",
    "    \n",
    "    \n",
    "    def reset_noise(self):\n",
    "        for name, module in self.named_children():\n",
    "            if 'fc' in name:\n",
    "                module.resetNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy(epsilon,state,net,atoms):\n",
    "    if(np.random.random()<epsilon):\n",
    "        action = np.random.randint(ACT_SHAPE)\n",
    "    else:\n",
    "        #Finding the expected value of each action (sum(pi*zi))\n",
    "        qvalues = net(state)\n",
    "        expected_values = torch.matmul(qvalues,atoms)\n",
    "        action = torch.argmax(expected_values).item()\n",
    "    return action    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env    = make_atari('PongNoFrameskip-v4')\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)\n",
    "VMIN = -10\n",
    "VMAX = 10\n",
    "N_ATOMS = 51\n",
    "atoms = torch.linspace(VMIN,VMAX,N_ATOMS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net,evaluation_episodes):\n",
    "    state = env.reset()\n",
    "    net.eval()\n",
    "    state = torch.Tensor(state).cuda()\n",
    "    state = state.unsqueeze(0)\n",
    "    rewards = []\n",
    "    count = 0\n",
    "    episode_reward = 0\n",
    "    while(True):\n",
    "        action = eps_greedy(0,state,net,atoms)  \n",
    "        next_state, reward, done,info = env.step(action)\n",
    "        next_state = torch.Tensor(next_state).unsqueeze(0).cuda()\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            count += 1\n",
    "            print('Episode ',count,end=' ')\n",
    "            print('Reward ',episode_reward)\n",
    "            rewards.append(episode_reward)\n",
    "            state = env.reset()\n",
    "            state = torch.Tensor(state).cuda()\n",
    "            state = state.unsqueeze(0)\n",
    "            episode_reward = 0\n",
    "        if(count == evaluation_episodes):\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "\n",
    "    return sum(rewards)/len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  1 Reward  19.0\n",
      "Episode  2 Reward  19.0\n",
      "Episode  3 Reward  15.0\n",
      "Episode  4 Reward  19.0\n",
      "Episode  5 Reward  19.0\n",
      "Episode  6 Reward  15.0\n",
      "Episode  7 Reward  19.0\n",
      "Episode  8 Reward  19.0\n",
      "Episode  9 Reward  18.0\n",
      "Episode  10 Reward  15.0\n"
     ]
    }
   ],
   "source": [
    "net = QNet(env.observation_space.shape,env.action_space.n,51).cuda()\n",
    "net.load_state_dict(torch.load('./rainbow-logs/rb-model10000000.pth'))\n",
    "net.eval()\n",
    "test(net,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
