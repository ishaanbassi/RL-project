{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from wrappers import make_atari, wrap_deepmind, wrap_pytorch\n",
    "import queue\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd \n",
    "import os \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, init_std = 0.5):\n",
    "        super(NoisyNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.weights_mu = nn.Parameter(torch.empty(out_channels, in_channels)) \n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_channels))\n",
    "        self.weights_sigma = nn.Parameter(torch.empty(out_channels, in_channels))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_channels))\n",
    "        self.register_buffer('weight_epsilon',torch.empty(out_channels, in_channels))\n",
    "        self.register_buffer('bias_epsilon',torch.empty(out_channels))\n",
    "        self.init_std = init_std\n",
    "        self.resetNoise()\n",
    "        self.resetWeights()\n",
    "       \n",
    "   \n",
    "    def resetNoise(self):\n",
    "        epsilon_i = torch.randn(self.in_channels)\n",
    "        epsilon_i = epsilon_i.sign().mul_(epsilon_i.abs().sqrt_())\n",
    "        epsilon_j = torch.randn(self.out_channels)\n",
    "        epsilon_j = epsilon_j.sign().mul_(epsilon_j.abs().sqrt_())\n",
    "        self.weight_epsilon.copy_(epsilon_j.ger(epsilon_i))\n",
    "        self.bias_epsilon.copy_(epsilon_j)\n",
    "       \n",
    "   \n",
    "    def resetWeights(self):\n",
    "        mu_range = 1 / math.sqrt(self.in_channels)\n",
    "        self.weights_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weights_sigma.data.fill_(self.init_std / math.sqrt(self.in_channels))\n",
    "        self.bias_sigma.data.fill_(self.init_std / math.sqrt(self.out_channels))\n",
    "       \n",
    "   \n",
    "    def forward(self, input):\n",
    "        if not self.training:\n",
    "            return F.linear(input, self.weights_mu, self.bias_mu)\n",
    "        else:\n",
    "            weights = self.weights_mu + self.weights_sigma * self.weight_epsilon\n",
    "            biases = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "            return F.linear(input, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(torch.nn.Module):\n",
    "    def __init__(self,obs_shape,act_shape,atoms):\n",
    "        super(QNet, self).__init__()\n",
    "        self.atoms = atoms\n",
    "        self.act_shape = act_shape\n",
    "\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.selu = nn.SELU()\n",
    "#         self.fc1 = nn.Linear(7*7*64,512)\n",
    "#         self.fc2 = nn.Linear(512,1)\n",
    "#         self.fc3 = nn.Linear(7*7*64,512)\n",
    "#         self.fc4 = nn.Linear(512,act_shape)\n",
    "        self.fc1 = NoisyNet(7*7*64,512)\n",
    "        self.fc2 = NoisyNet(512,atoms)\n",
    "        self.fc3 = NoisyNet(7*7*64,512)\n",
    "        self.fc4 = NoisyNet(512,act_shape*atoms)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x/255\n",
    "        \n",
    "        #Conv\n",
    "        x = self.conv1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.selu(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        #Fc\n",
    "        x1 = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        v = self.fc2(x)\n",
    "        \n",
    "        x1 = self.fc3(x1)\n",
    "        x1 = self.selu(x1)\n",
    "        adv = self.fc4(x1)\n",
    "        \n",
    "        #Reshaping value and advantage functions to add probabilities of each atom for each action\n",
    "        value = v.view(v.shape[0],1,self.atoms)\n",
    "        adv = adv.view(adv.shape[0],self.act_shape,self.atoms)\n",
    "        \n",
    "        q_s_a = value + adv - adv.mean(1,keepdim=True)\n",
    "        \n",
    "        #probability of each atom for all actions\n",
    "        q_s_a = self.softmax(q_s_a)\n",
    "        \n",
    "        return q_s_a\n",
    "    \n",
    "    \n",
    "    def reset_noise(self):\n",
    "        for name, module in self.named_children():\n",
    "            if 'fc' in name:\n",
    "                module.resetNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy(epsilon,state,net,atoms):\n",
    "    if(np.random.random()<epsilon):\n",
    "        action = np.random.randint(ACT_SHAPE)\n",
    "    else:\n",
    "        #Finding the expected value of each action (sum(pi*zi))\n",
    "        qvalues = net(state)\n",
    "        expected_values = torch.matmul(qvalues,atoms)\n",
    "        action = torch.argmax(expected_values).item()\n",
    "    return action    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env    = make_atari('PongNoFrameskip-v4')\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)\n",
    "VMIN = -10\n",
    "VMAX = 10\n",
    "N_ATOMS = 51\n",
    "atoms = torch.linspace(VMIN,VMAX,N_ATOMS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net,evaluation_episodes):\n",
    "    state = env.reset()\n",
    "    net.eval()\n",
    "    state = torch.Tensor(state).cuda()\n",
    "    state = state.unsqueeze(0)\n",
    "    rewards = []\n",
    "    count = 0\n",
    "    episode_reward = 0\n",
    "    while(True):\n",
    "        action = eps_greedy(0,state,net,atoms)  \n",
    "        next_state, reward, done,info = env.step(action)\n",
    "        next_state = torch.Tensor(next_state).unsqueeze(0).cuda()\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            count += 1\n",
    "            print('Episode ',count,end=' ')\n",
    "            print('Reward ',episode_reward)\n",
    "            rewards.append(episode_reward)\n",
    "            state = env.reset()\n",
    "            state = torch.Tensor(state).cuda()\n",
    "            state = state.unsqueeze(0)\n",
    "            episode_reward = 0\n",
    "        if(count == evaluation_episodes):\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "\n",
    "    return sum(rewards)/len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  1 Reward  18.0\n",
      "Episode  2 Reward  18.0\n",
      "Episode  3 Reward  19.0\n",
      "Episode  4 Reward  18.0\n",
      "Episode  5 Reward  18.0\n",
      "Episode  6 Reward  18.0\n",
      "Episode  7 Reward  18.0\n",
      "Episode  8 Reward  18.0\n",
      "Episode  9 Reward  19.0\n",
      "Episode  10 Reward  19.0\n",
      "Episode  11 Reward  18.0\n",
      "Episode  12 Reward  18.0\n",
      "Episode  13 Reward  19.0\n",
      "Episode  14 Reward  18.0\n",
      "Episode  15 Reward  19.0\n",
      "Episode  16 Reward  19.0\n",
      "Episode  17 Reward  18.0\n",
      "Episode  18 Reward  18.0\n",
      "Episode  19 Reward  18.0\n",
      "Episode  20 Reward  18.0\n",
      "Episode  21 Reward  18.0\n",
      "Episode  22 Reward  18.0\n",
      "Episode  23 Reward  18.0\n",
      "Episode  24 Reward  18.0\n",
      "Episode  25 Reward  18.0\n",
      "Episode  26 Reward  18.0\n",
      "Episode  27 Reward  18.0\n",
      "Episode  28 Reward  18.0\n",
      "Episode  29 Reward  19.0\n",
      "Episode  30 Reward  18.0\n",
      "Episode  31 Reward  18.0\n",
      "Episode  32 Reward  18.0\n",
      "Episode  33 Reward  19.0\n",
      "Episode  34 Reward  18.0\n",
      "Episode  35 Reward  18.0\n",
      "Episode  36 Reward  18.0\n",
      "Episode  37 Reward  18.0\n",
      "Episode  38 Reward  18.0\n",
      "Episode  39 Reward  19.0\n",
      "Episode  40 Reward  18.0\n",
      "Episode  41 Reward  18.0\n",
      "Episode  42 Reward  19.0\n",
      "Episode  43 Reward  19.0\n",
      "Episode  44 Reward  19.0\n",
      "Episode  45 Reward  19.0\n",
      "Episode  46 Reward  18.0\n",
      "Episode  47 Reward  18.0\n",
      "Episode  48 Reward  18.0\n",
      "Episode  49 Reward  18.0\n",
      "Episode  50 Reward  18.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(np.random.randint(1, 10000)) \n",
    "if torch.cuda.is_available():\n",
    "    torch.manual_seed(np.random.randint(1, 10000))\n",
    "net = QNet(env.observation_space.shape,env.action_space.n,51).cuda()\n",
    "net.load_state_dict(torch.load('./rainbow_imp-logs/rb-model4400000.pth'))\n",
    "net.eval()\n",
    "test(net,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.read_csv('./rainbow-logs/rewards.csv')\n",
    "rdf2 = pd.read_csv('./rainbow-logs/rewards2.csv')\n",
    "ldf = pd.read_csv('./rainbow-logs/losses.csv')\n",
    "ldf2 = pd.read_csv('./rainbow-logs/losses2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_final = pd.concat([rdf,rdf2],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5889, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>episode</th>\n",
       "      <th>rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762</td>\n",
       "      <td>1</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1526</td>\n",
       "      <td>2</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2288</td>\n",
       "      <td>3</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3049</td>\n",
       "      <td>4</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808</td>\n",
       "      <td>5</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  episode  rewards\n",
       "0    762        1    -21.0\n",
       "1   1526        2    -21.0\n",
       "2   2288        3    -21.0\n",
       "3   3049        4    -21.0\n",
       "4   3808        5    -21.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_final.to_csv(\"./rainbow-logs/rewards_comb.csv\",sep = ',', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_final = pd.concat([ldf,ldf2],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9770, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
